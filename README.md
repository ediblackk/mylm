# My Little Minion (mylm)

[![Rust](https://img.shields.io/badge/rust-stable-brightgreen.svg)](https://www.rust-lang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Terminal AI](https://img.shields.io/badge/Terminal-AI-blue.svg)](.)

<p align="center">
  <img src="assets/logo.png" alt="mylm Logo" width="180">
</p>

## The AI assistant that actually understands your terminal

**mylm** is a privacy-focused, multi-agent terminal AI assistant built in Rust. It sees your terminal, remembers your projects, delegates tasks to specialized sub-agents, and safely executes commandsâ€”all while keeping you in control.

### Features

- **Persistent vector memory** â€” LanceDB with semantic search across sessions
- **Multi-agent orchestration** â€” Parallel workers with job tracking
- **Full terminal context** â€” tmux integration, zero manual context sharing
- **Background job system** â€” Async delegation, non-blocking
- **Safety-first execution** â€” Allowlists, approval workflow, PTY isolation
- **Lightweight & fast** â€” Rust-native, sub-100ms cold start

---

## Quick Start

### Installation

git clone https://github.com/ediblackk/mylm.git
cd mylm
chmod +x install.sh
./install.sh

Installs to `~/.local/bin` without sudo.

### First Use

ai                    # Start the interactive hub
ai "question"         # Ask a one-off question
ai pop                # Pop terminal context (requires tmux)
ai interactive        # Full TUI session

---

## âœ¨ What Makes mylm Special

### ğŸ¯ `ai pop` â€” Context Magic
Your command fails. Instead of copying error messages, just type:

ai pop

mylm captures your terminal history, working directory, git state, environment variables, and recent commands. The AI sees exactly what you see. **No setup. No copy-paste. Just context.**

*Requires tmux (we'll help you set it up).*

### ğŸ§  Multi-Agent System
Most AI assistants are a single brain trying to do everything. mylm uses an **orchestrator-worker pattern**:

- **Orchestrator** plans and delegates
- **Worker agents** execute subtasks in parallel
- **Delegate tool** spawns specialized agents with their own toolsets
- **Job registry** tracks progress across all agents

Research a library while refactoring codeâ€”all at once.

### ğŸ”„ PaCoRe: Parallel Consensus Reasoning
(https://github.com/stepfun-ai/PaCoRe)
When accuracy matters, mylm can run **multi-round reasoning**:
1. Spawn multiple parallel LLM calls with different reasoning paths
2. Let them critique and build on each other's answers
3. Synthesize a consensus response

Better answers for complex debugging and architecture decisions.

### ğŸ›¡ï¸ Safety-First Execution
Every command goes through:
1. **Static analysis** â€” Pattern-based risk detection
2. **Allowlist checking** â€” Known safe commands
3. **User approval** â€” You see it before it runs

Run with `--execute` for trusted commands. Use `--force` only when you know what you're doing.

### ğŸŒ 10+ Built-in Tools
- **shell** â€” Execute with safety checks
- **git** â€” Status, log, diff analysis
- **fs** â€” Read/write files
- **web_search** â€” Real-time information
- **crawl** â€” Deep documentation extraction
- **memory** â€” Store and retrieve knowledge
- **delegate** â€” Spawn sub-agents
- **state** â€” Persistent key-value storage
- **terminal_sight** â€” Capture terminal state
- **system** â€” Resource monitoring

### âš¡ Built for Speed
- **Rust** â€” Zero-cost abstractions, memory safety
- **Async tokio** â€” Non-blocking I/O throughout
- **Optimized profiles** â€” Fast compile in dev, LTO in release
- **Sub-100ms** cold start to interactive

---

## ğŸ”’ Security & Privacy

- **Local-first**: Vector DB runs locally (LanceDB)
- **No telemetry**: Your data stays yours
- **Command safety**: Approval workflow, allowlists, pattern detection
- **API key handling**: Stored in config, never logged
- **Sandboxed execution**: Commands run in isolated PTY

---

## ğŸ› ï¸ Supported Providers

**Local (Free, Private):**
- Ollama
- LM Studio
- HuggingFace (via inference API)

**Cloud (API Key Required):**
- Any OpenAI Compatible endpoint
- Google Gemini 3
- OpenAI (GPT-5.2)
- Anthropic (Claude Sonnet 4.5)
- DeepSeek V3.2
- StepFun 3.5 Flash
- Kimi K2.5 (Moonshot)

---

## ğŸ™ Acknowledgements

Built with assistance from every AI that would talk to me: Claude, GPT, Gemini,
Kimi, DeepSeek, StepFun, Z.AI, MiniMax and probably others I've forgotten. Also 147 Rust crates I didn't write. And Linux/Debian.And VS Code. And ASUS. And liters of coffee.

---

## ğŸ“„ License

MIT â€” See [LICENSE](LICENSE) for details.