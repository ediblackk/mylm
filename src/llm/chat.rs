//! Chat message types for LLM communication
//!
//! Defines the message structures used for chat completions,
//! supporting both OpenAI-compatible and Google Gemini APIs.

use serde::{Deserialize, Serialize};
use regex::Regex;

/// Role of the message sender
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum MessageRole {
    /// System message (instructions for the model)
    System,
    /// User message
    User,
    /// Assistant message (model response)
    Assistant,
    /// Tool message (result from tool execution)
    Tool,
}

impl MessageRole {
    pub fn as_str(&self) -> &'static str {
        match self {
            MessageRole::System => "system",
            MessageRole::User => "user",
            MessageRole::Assistant => "assistant",
            MessageRole::Tool => "tool",
        }
    }
}

/// A single message in a conversation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatMessage {
    /// Role of the message sender
    pub role: MessageRole,
    /// Content of the message
    pub content: String,
    /// Optional name for the message author
    #[serde(skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Tool call ID (required for role=tool)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_call_id: Option<String>,
    /// Tool calls generated by the model
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_calls: Option<Vec<ToolCall>>,
}

#[allow(dead_code)]
impl ChatMessage {
    /// Create a new user message
    pub fn user(content: impl Into<String>) -> Self {
        ChatMessage {
            role: MessageRole::User,
            content: content.into(),
            name: None,
            tool_call_id: None,
            tool_calls: None,
        }
    }

    /// Create a new system message
    pub fn system(content: impl Into<String>) -> Self {
        ChatMessage {
            role: MessageRole::System,
            content: content.into(),
            name: None,
            tool_call_id: None,
            tool_calls: None,
        }
    }

    /// Create a new assistant message
    pub fn assistant(content: impl Into<String>) -> Self {
        ChatMessage {
            role: MessageRole::Assistant,
            content: content.into(),
            name: None,
            tool_call_id: None,
            tool_calls: None,
        }
    }
    /// Create a new tool result message
    pub fn tool(tool_call_id: impl Into<String>, name: impl Into<String>, content: impl Into<String>) -> Self {
        ChatMessage {
            role: MessageRole::Tool,
            content: content.into(),
            name: Some(name.into()),
            tool_call_id: Some(tool_call_id.into()),
            tool_calls: None,
        }
    }
}

/// A tool call generated by the model
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCall {
    pub id: String,
    #[serde(rename = "type")]
    pub type_: String,
    pub function: ToolCallFunction,
}

/// Function information for a tool call
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCallFunction {
    pub name: String,
    pub arguments: String,
}

/// Request body for chat completion
#[derive(Debug, Serialize, Deserialize)]
pub struct ChatRequest {
    /// ID of the model to use
    pub model: String,
    /// List of messages in the conversation
    pub messages: Vec<ChatMessage>,
    /// Maximum tokens to generate
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    /// Temperature for sampling (0-2)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    /// Whether to stream the response
    #[serde(default = "default_stream")]
    pub stream: bool,
    /// Optional stop sequences
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stop: Option<Vec<String>>,
    /// Optional tools for the model to use
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tools: Option<Vec<ChatTool>>,
}

/// Tool definition for chat requests
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatTool {
    #[serde(rename = "type")]
    pub type_: String,
    pub function: ChatFunction,
}

/// Function definition for tools
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatFunction {
    pub name: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub description: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub parameters: Option<serde_json::Value>,
}

fn default_stream() -> bool {
    false
}

#[allow(dead_code)]
impl ChatRequest {
    /// Create a new chat request
    pub fn new(model: String, messages: Vec<ChatMessage>) -> Self {
        ChatRequest {
            model,
            messages,
            max_tokens: None,
            temperature: None,
            stream: false,
            stop: None,
            tools: None,
        }
    }

    /// Add tools to the request
    pub fn with_tools(mut self, tools: Vec<ChatTool>) -> Self {
        self.tools = Some(tools);
        self
    }

    /// Add a system message
    pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self {
        self.messages.insert(0, ChatMessage::system(prompt));
        self
    }

    /// Set max tokens
    pub fn with_max_tokens(mut self, tokens: u32) -> Self {
        self.max_tokens = Some(tokens);
        self
    }

    /// Set temperature
    pub fn with_temperature(mut self, temp: f32) -> Self {
        self.temperature = Some(temp.clamp(0.0, 2.0));
        self
    }

    /// Enable streaming
    pub fn with_streaming(mut self, stream: bool) -> Self {
        self.stream = stream;
        self
    }
}

/// Response from chat completion
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    /// Unique identifier for the response
    pub id: String,
    /// Type of response (e.g., "chat.completion")
    pub object: String,
    /// Unix timestamp of creation
    pub created: u64,
    /// Model that generated the response
    pub model: String,
    /// List of generated completions
    pub choices: Vec<Choice>,
    /// Usage statistics
    #[serde(skip_serializing_if = "Option::is_none")]
    pub usage: Option<Usage>,
}

impl ChatResponse {
    /// Extract memories from the response content using [MEMORY: <content>] tags
    #[allow(dead_code)]
    pub fn extract_memories(&self) -> Vec<String> {
        let content = self.content();
        let re = Regex::new(r"\[MEMORY:\s*(.*?)]").unwrap();
        re.captures_iter(&content)
            .map(|cap| cap[1].trim().to_string())
            .filter(|s| !s.is_empty())
            .collect()
    }

    /// Extract search queries from the response content using [SEARCH: <query>] tags
    #[allow(dead_code)]
    pub fn extract_searches(&self) -> Vec<String> {
        let content = self.content();
        let re = Regex::new(r"\[SEARCH:\s*(.*?)]").unwrap();
        re.captures_iter(&content)
            .map(|cap| cap[1].trim().to_string())
            .filter(|s| !s.is_empty())
            .collect()
    }

    /// Returns the content with memory/search tags removed for display
    #[allow(dead_code)]
    pub fn display_content(&self) -> String {
        let content = self.content();
        let re_mem = Regex::new(r"\[MEMORY:\s*.*?]\n?").unwrap();
        let re_search = Regex::new(r"\[SEARCH:\s*.*?]\n?").unwrap();
        let cleaned = re_mem.replace_all(&content, "");
        let cleaned = re_search.replace_all(&cleaned, "");
        cleaned.trim().to_string()
    }

    /// Helper to get the content of the first choice
    pub fn content(&self) -> String {
        self.choices
            .first()
            .map(|c| c.message.content.clone())
            .unwrap_or_default()
    }
}

/// A single completion choice
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Choice {
    /// Index of this choice
    pub index: u32,
    /// The generated message
    pub message: ChatMessage,
    /// Reason for stopping
    #[serde(skip_serializing_if = "Option::is_none")]
    pub finish_reason: Option<String>,
}

/// Token usage statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    /// Tokens in the prompt
    pub prompt_tokens: u32,
    /// Tokens in the completion
    pub completion_tokens: u32,
    /// Total tokens used
    pub total_tokens: u32,
}

/// Stream event types for streaming responses
#[derive(Debug, Clone)]
#[allow(dead_code)]
pub enum StreamEvent {
    /// Content chunk received
    Content(String),
    /// Streaming is complete
    Done,
    /// Token usage information
    Usage(crate::llm::TokenUsage),
    /// Error occurred
    Error(String),
}

#[allow(dead_code)]
impl StreamEvent {
    /// Check if this is a content event
    pub fn is_content(&self) -> bool {
        match self {
            StreamEvent::Content(_) => true,
            _ => false,
        }
    }

    /// Check if streaming is done
    pub fn is_done(&self) -> bool {
        match self {
            StreamEvent::Done => true,
            _ => false,
        }
    }

    /// Get content if available
    pub fn content(&self) -> Option<&str> {
        match self {
            StreamEvent::Content(s) => Some(s),
            _ => None,
        }
    }
}
